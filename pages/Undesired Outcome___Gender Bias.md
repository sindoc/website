- When [[the output of AI]] drifts from [[human values]]
- Includes
	- [[stereotypical traits]]
		- Describing men as strong, logical, or assertive and women as emotional, nurturing, or passive.
	- [[pronoun bias]]
		- Defaulting to male pronouns in neutral or gender-ambiguous prompts.
	- [[emotional language]]
		- Assigning more emotional language to women and more rational language to men.
	- [[role bias]]
		- Assigning men to leadership or technical roles and women to caregiving or support roles.
	- [[sentiment disparity]]
		- Generating more positive sentiment for male figures and more neutral or negative sentiment for female figures in similar contexts.
- Mitigated by
	- [[Gender Bias Detection]]
	-